package generators

const coordinatorTemplate = `
package main

import (
	"context"
	"errors"
	"strings"

	"github.com/aws/aws-lambda-go/lambda"
	"github.com/aws/aws-lambda-go/lambdacontext"
	log "github.com/sirupsen/logrus"

	"github.com/josenarvaezp/displ/internal/lambdas"
)

var c *lambdas.Coordinator

func init() {
	// set logger
	log.SetLevel(log.ErrorLevel)

	var err error
	c, err = lambdas.NewCoordinator(true)
	if err != nil {
		log.WithError(err).Fatal("Error starting coordinator")
		return
	}
}

func HandleRequest(ctx context.Context, request lambdas.CoordinatorInput) error {
	// get data from context
	lc, ok := lambdacontext.FromContext(ctx)
	if !ok {
		return errors.New("Error getting lambda context")
	}
	c.AccountID = strings.Split(lc.InvokedFunctionArn, ":")[4]
	c.JobID = request.JobID
	c.NumMappers = int64(request.NumMappers)
	c.NumQueues = int64(request.NumQueues)

	coordinatorLogger := log.WithFields(log.Fields{
		"Job ID": c.JobID.String(),
	})

	// waits until mappers are done
	if err := c.AreMappersDone(ctx); err != nil {
		coordinatorLogger.WithError(err).Error("Error reading mappers done queue")
		return err
	}

	// invoke reducers
	if err := c.InvokeReducers(ctx, {{.LambdaAggregator}}); err != nil {
		coordinatorLogger.WithError(err).Error("Error invoking reducers")
		return nil
	}

	// wait until reducers are done
	if err := c.AreReducersDone(ctx); err != nil {
		coordinatorLogger.WithError(err).Error("Error reading reducers done queue")
		return err
	}

	// indicate reducers are done
	if err := c.WriteDoneObject(ctx); err != nil {
		coordinatorLogger.WithError(err).Error("Error writing done signal")
		return err
	}

	return nil
}

func main() {
	lambda.Start(HandleRequest)
}
`

const dockerfileTemplate = `
FROM golang as build

ARG CGO_ENABLED=0

# create work directory
WORKDIR /build

# install tools
RUN apt-get update && apt-get install -y upx

# add dependancies
ADD go.mod go.sum ./
RUN go mod download

# add source files
ADD ./pkg ./pkg
ADD ./internal ./internal
ADD ./build/lambda_gen/{{.JobID}} ./build/lambda_gen/{{.JobID}}
ADD ./{{.Workspace}} ./{{.Workspace}}

# build lambdas
RUN go build -ldflags "-s -w" -o /build/lambdas/ ./build/lambda_gen/{{.JobID}}/{{.FunctionType}}/{{.FunctionName}}.go

# compress
RUN upx --best --lzma /build/lambdas/{{.FunctionName}}

# Build runtime for {{.FunctionType}}_{{.JobID}}
FROM alpine as {{.FunctionType}}

COPY --from=build /build/lambdas/{{.FunctionName}} /lambdas/{{.FunctionName}}

ENTRYPOINT [ "/lambdas/{{.FunctionName}}" ]
`

const mapTemplate = `
// DO NOT EDIT: THIS HAS BEEN AUTOGENERATED

package main

import (
	"context"
	"errors"
	"os"
	"strings"

	"github.com/aws/aws-lambda-go/lambda"
	"github.com/aws/aws-lambda-go/lambdacontext"
	log "github.com/sirupsen/logrus"

	"github.com/josenarvaezp/displ/internal/lambdas"
	"github.com/josenarvaezp/displ/pkg/aggregators"
	"{{.PackagePath}}"
)

var m *lambdas.Mapper

func init() {
	// set logger
	log.SetLevel(log.ErrorLevel)

	var err error
	m, err = lambdas.NewMapper(true)
	if err != nil {
		log.WithError(err).Fatal("Error starting mapper")
		return
	}
}

func HandleRequest(ctx context.Context, request lambdas.MapperInput) error {
	// get data from context
	lc, ok := lambdacontext.FromContext(ctx)
	if !ok {
		return errors.New("Error getting lambda context")
	}
	m.AccountID = strings.Split(lc.InvokedFunctionArn, ":")[4]
	m.JobID = request.JobID
	m.MapID = request.Mapping.MapID
	m.NumQueues = request.Mapping.NumQueues

	mapperLogger := log.WithFields(log.Fields{
		"Job ID": m.JobID.String(),
		"Map ID": m.MapID.String(),
	})

	// keep a dictionary with the number of batches per queue
	batchMetadata := make(map[int]int64)

	for _, object := range request.Mapping.Objects {
		// download file
		filename, err := m.DownloadFile(object)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error downloading file")
			return err
		}

		// user function starts here
		mapOutput := runMapSumMapper(*filename, {{.PackageName}}.{{.Function}})

		// send output to reducers via queues
		err = m.EmitMapSum(ctx, mapOutput, batchMetadata)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error sending map output to reducers")
			return err
		}

		// clean up file in /tmp
		err = os.Remove(*filename)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error cleaning file from /temp")
			return err
		}
	}

	// send batch metadata to sqs
	if err := m.SendBatchMetadata(ctx, batchMetadata); err != nil {
		mapperLogger.WithError(err).Error("Error sending metadata to streams")
		return err
	}

	// send event to queue indicating this mapper has completed
	if err := m.SendFinishedEvent(ctx); err != nil {
		mapperLogger.WithError(err).Error("Error sending done event to stream")
		return err
	}

	return nil
}

func main() {
	lambda.Start(HandleRequest)
}

func runMapper(filename string, userMap func(filename string) map[string]int) map[string]int {
	return userMap(filename)
}

func runMapSumMapper(filename string, userMap func(filename string) aggregators.MapSum) aggregators.MapSum {
	return userMap(filename)
}
`

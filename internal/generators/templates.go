package generators

const mapCoordinatorTemplate = `
// Code generated by ribble DO NOT EDIT.
// |\   \\\\__     o
// | \_/    o \    o 
// > _   (( <_  oo  
// | / \__+___/      
// |/     |/

package main

import (
	"context"

	"github.com/aws/aws-lambda-go/lambda"
	log "github.com/sirupsen/logrus"

	"github.com/josenarvaezp/displ/internal/lambdas"
)

var c *lambdas.Coordinator

func init() {
	// set logger
	log.SetLevel(log.ErrorLevel)

	var err error
	c, err = lambdas.NewCoordinator(false)
	if err != nil {
		log.WithError(err).Fatal("Error starting coordinator")
		return
	}
}

func HandleRequest(ctx context.Context, request lambdas.CoordinatorInput) error {
	// update coordinator
	c.UpdateCoordinatorWithRequest(ctx, request)

	// set coordinator logger
	coordinatorLogger := log.WithFields(log.Fields{
		"Job ID": c.JobID.String(),
	})

	// waits until mappers are done
	if err := c.AreMappersDone(ctx); err != nil {
		coordinatorLogger.WithError(err).Error("Error reading mappers done queue")
		return err
	}

	// invoke reducers
	if err := c.InvokeReducers(ctx, "{{.LambdaAggregator}}"); err != nil {
		coordinatorLogger.WithError(err).Error("Error invoking reducers")
		return nil
	}

	// wait until reducers are done
	if err := c.AreReducersDone(ctx); err != nil {
		coordinatorLogger.WithError(err).Error("Error reading reducers done queue")
		return err
	}

	// indicate reducers are done
	if err := c.WriteDoneObject(ctx); err != nil {
		coordinatorLogger.WithError(err).Error("Error writing done signal")
		return err
	}

	return nil
}

func main() {
	lambda.Start(HandleRequest)
}

`

const valueCoordinatorTemplate = `
// Code generated by ribble DO NOT EDIT.
// |\   \\\\__     o
// | \_/    o \    o
// > _   (( <_  oo
// | / \__+___/
// |/     |/

package main

import (
	"context"

	"github.com/aws/aws-lambda-go/lambda"
	log "github.com/sirupsen/logrus"

	"github.com/josenarvaezp/displ/internal/lambdas"
)

var c *lambdas.Coordinator

func init() {
	// set logger
	log.SetLevel(log.ErrorLevel)

	var err error
	c, err = lambdas.NewCoordinator(false)
	if err != nil {
		log.WithError(err).Fatal("Error starting coordinator")
		return
	}
}

func HandleRequest(ctx context.Context, request lambdas.CoordinatorInput) error {
	// update coordinator
	c.UpdateCoordinatorWithRequest(ctx, request)

	// set coordinator logger
	coordinatorLogger := log.WithFields(log.Fields{
		"Job ID": c.JobID.String(),
	})

	// waits until mappers are done
	if err := c.AreMappersDone(ctx); err != nil {
		coordinatorLogger.WithError(err).Error("Error reading mappers done queue")
		return err
	}

	// invoke reducers
	if err := c.InvokeReducers(ctx, "{{.LambdaAggregator}}"); err != nil {
		coordinatorLogger.WithError(err).Error("Error invoking reducers")
		return nil
	}

	// wait until reducers are done
	if err := c.AreReducersDone(ctx); err != nil {
		coordinatorLogger.WithError(err).Error("Error reading reducers done queue")
		return err
	}

	// invoke final reducer
	if err := c.InvokeReducer(ctx, "{{.LambdaFinalAggregator}}"); err != nil {
		coordinatorLogger.WithError(err).Error("Error invoking final reducer")
		return nil
	}

	return nil
}

func main() {
	lambda.Start(HandleRequest)
}

`

const dockerfileTemplate = `
# Code generated by ribble DO NOT EDIT.
# |\   \\\\__     o
# | \_/    o \    o 
# > _   (( <_  oo  
# | / \__+___/      
# |/     |/

FROM golang as build

ARG CGO_ENABLED=0

# create work directory
WORKDIR /build

# install tools
RUN apt-get update && apt-get install -y upx

# add dependancies
ADD go.mod go.sum ./
RUN go mod download

# add source files
ADD ./pkg ./pkg
ADD ./internal ./internal
ADD ./build/lambda_gen/{{.JobID}} ./build/lambda_gen/{{.JobID}}
ADD ./{{.Workspace}} ./{{.Workspace}}

# build lambdas
RUN env GOOS=linux GOARCH=amd64 go build -ldflags "-s -w" -o /build/lambdas/ ./build/lambda_gen/{{.JobID}}/{{.FunctionType}}/{{.FunctionName}}.go

# compress
RUN upx --best --lzma /build/lambdas/{{.FunctionName}}

# Build runtime for {{.FunctionType}}_{{.JobID}}
FROM alpine as {{.FunctionType}}

COPY --from=build /build/lambdas/{{.FunctionName}} /lambdas/{{.FunctionName}}

ENTRYPOINT [ "/lambdas/{{.FunctionName}}" ]
`

const mapSumTemplate = `
// Code generated by ribble DO NOT EDIT.
// |\   \\\\__     o
// | \_/    o \    o 
// > _   (( <_  oo  
// | / \__+___/      
// |/     |/

package main

import (
	"context"
	"os"

	"github.com/aws/aws-lambda-go/lambda"
	log "github.com/sirupsen/logrus"

	"github.com/josenarvaezp/displ/internal/lambdas"
	"{{.PackagePath}}"
)

var m *lambdas.Mapper

func init() {
	// set logger
	log.SetLevel(log.ErrorLevel)

	var err error
	m, err = lambdas.NewMapper(false)
	if err != nil {
		log.WithError(err).Fatal("Error starting mapper")
		return
	}
}

func HandleRequest(ctx context.Context, request lambdas.MapperInput) error {
	// update mapper
	m.UpdateMapperWithRequest(ctx, request)

	// set mapper logger
	mapperLogger := log.WithFields(log.Fields{
		"Job ID": m.JobID.String(),
		"Map ID": m.MapID.String(),
	})

	// keep a dictionary with the number of batches per queue
	batchMetadata := make(map[int]int64)

	for _, object := range request.Mapping.Objects {
		// download file
		filename, err := m.DownloadFile(object)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error downloading file")
			return err
		}

		// user function starts here
		mapOutput := lambdas.RunMapSumMapper(*filename, {{.PackageName}}.{{.Function}})

		// send output to reducers via queues
		err = m.EmitMap(ctx, mapOutput, batchMetadata)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error sending map output to reducers")
			return err
		}

		// clean up file in /tmp
		err = os.Remove(*filename)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error cleaning file from /temp")
			return err
		}
	}

	// send batch metadata to sqs
	if err := m.SendBatchMetadata(ctx, batchMetadata); err != nil {
		mapperLogger.WithError(err).Error("Error sending metadata to streams")
		return err
	}

	// send event to queue indicating this mapper has completed
	if err := m.SendFinishedEvent(ctx); err != nil {
		mapperLogger.WithError(err).Error("Error sending done event to stream")
		return err
	}

	return nil
}

func main() {
	lambda.Start(HandleRequest)
}

`
const mapMaxTemplate = `
// Code generated by ribble DO NOT EDIT.
// |\   \\\\__     o
// | \_/    o \    o 
// > _   (( <_  oo  
// | / \__+___/      
// |/     |/

package main

import (
	"context"
	"os"

	"github.com/aws/aws-lambda-go/lambda"
	log "github.com/sirupsen/logrus"

	"github.com/josenarvaezp/displ/internal/lambdas"
	"{{.PackagePath}}"
)

var m *lambdas.Mapper

func init() {
	// set logger
	log.SetLevel(log.ErrorLevel)

	var err error
	m, err = lambdas.NewMapper(false)
	if err != nil {
		log.WithError(err).Fatal("Error starting mapper")
		return
	}
}

func HandleRequest(ctx context.Context, request lambdas.MapperInput) error {
	// update mapper
	m.UpdateMapperWithRequest(ctx, request)

	// set mapper logger
	mapperLogger := log.WithFields(log.Fields{
		"Job ID": m.JobID.String(),
		"Map ID": m.MapID.String(),
	})

	// keep a dictionary with the number of batches per queue
	batchMetadata := make(map[int]int64)

	for _, object := range request.Mapping.Objects {
		// download file
		filename, err := m.DownloadFile(object)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error downloading file")
			return err
		}

		// user function starts here
		mapOutput := lambdas.RunMapMaxMapper(*filename, {{.PackageName}}.{{.Function}})

		// send output to reducers via queues
		err = m.EmitMap(ctx, mapOutput, batchMetadata)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error sending map output to reducers")
			return err
		}

		// clean up file in /tmp
		err = os.Remove(*filename)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error cleaning file from /temp")
			return err
		}
	}

	// send batch metadata to sqs
	if err := m.SendBatchMetadata(ctx, batchMetadata); err != nil {
		mapperLogger.WithError(err).Error("Error sending metadata to streams")
		return err
	}

	// send event to queue indicating this mapper has completed
	if err := m.SendFinishedEvent(ctx); err != nil {
		mapperLogger.WithError(err).Error("Error sending done event to stream")
		return err
	}

	return nil
}

func main() {
	lambda.Start(HandleRequest)
}

`

const mapMinTemplate = `
// Code generated by ribble DO NOT EDIT.
// |\   \\\\__     o
// | \_/    o \    o 
// > _   (( <_  oo  
// | / \__+___/      
// |/     |/

package main

import (
	"context"
	"os"

	"github.com/aws/aws-lambda-go/lambda"
	log "github.com/sirupsen/logrus"

	"github.com/josenarvaezp/displ/internal/lambdas"
	"{{.PackagePath}}"
)

var m *lambdas.Mapper

func init() {
	// set logger
	log.SetLevel(log.ErrorLevel)

	var err error
	m, err = lambdas.NewMapper(false)
	if err != nil {
		log.WithError(err).Fatal("Error starting mapper")
		return
	}
}

func HandleRequest(ctx context.Context, request lambdas.MapperInput) error {
	// update mapper
	m.UpdateMapperWithRequest(ctx, request)

	// set mapper logger
	mapperLogger := log.WithFields(log.Fields{
		"Job ID": m.JobID.String(),
		"Map ID": m.MapID.String(),
	})

	// keep a dictionary with the number of batches per queue
	batchMetadata := make(map[int]int64)

	for _, object := range request.Mapping.Objects {
		// download file
		filename, err := m.DownloadFile(object)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error downloading file")
			return err
		}

		// user function starts here
		mapOutput := lambdas.RunMapMinMapper(*filename, {{.PackageName}}.{{.Function}})

		// send output to reducers via queues
		err = m.EmitMap(ctx, mapOutput, batchMetadata)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error sending map output to reducers")
			return err
		}

		// clean up file in /tmp
		err = os.Remove(*filename)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error cleaning file from /temp")
			return err
		}
	}

	// send batch metadata to sqs
	if err := m.SendBatchMetadata(ctx, batchMetadata); err != nil {
		mapperLogger.WithError(err).Error("Error sending metadata to streams")
		return err
	}

	// send event to queue indicating this mapper has completed
	if err := m.SendFinishedEvent(ctx); err != nil {
		mapperLogger.WithError(err).Error("Error sending done event to stream")
		return err
	}

	return nil
}

func main() {
	lambda.Start(HandleRequest)
}

`

const sumTemplate = `
// Code generated by ribble DO NOT EDIT.
// |\   \\\\__     o
// | \_/    o \    o
// > _   (( <_  oo
// | / \__+___/
// |/     |/

package main

import (
	"context"
	"os"

	"github.com/aws/aws-lambda-go/lambda"
	log "github.com/sirupsen/logrus"

	"github.com/josenarvaezp/displ/examples/wordcount"
	"github.com/josenarvaezp/displ/internal/lambdas"
	"github.com/josenarvaezp/displ/pkg/aggregators"
)

var m *lambdas.Mapper

func init() {
	// set logger
	log.SetLevel(log.ErrorLevel)

	var err error
	m, err = lambdas.NewMapper(false)
	if err != nil {
		log.WithError(err).Fatal("Error starting mapper")
		return
	}
}

func HandleRequest(ctx context.Context, request lambdas.MapperInput) error {
	// update mapper
	m.UpdateMapperWithRequest(ctx, request)

	// set mapper logger
	mapperLogger := log.WithFields(log.Fields{
		"Job ID": m.JobID.String(),
		"Map ID": m.MapID.String(),
	})

	totalSum := aggregators.Sum(0)

	// get queue partition
	queuePartition := m.GetRandomQueuePartition()

	for _, object := range request.Mapping.Objects {
		// download file
		filename, err := m.DownloadFile(object)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error downloading file")
			return err
		}

		// user function starts here
		mapOutput := lambdas.RunSumMapper(*filename, wordcount.SingleWordCount)

		// updated total sum
		totalSum = totalSum + mapOutput

		// clean up file in /tmp
		err = os.Remove(*filename)
		if err != nil {
			mapperLogger.
				WithFields(log.Fields{
					"Bucket": object.Bucket,
					"Object": object.Key,
				}).
				WithError(err).
				Error("Error cleaning file from /temp")
			return err
		}
	}

	// send output to reducers via queues
	err := m.EmitValue(ctx, queuePartition, totalSum.Int())
	if err != nil {
		mapperLogger.
			WithError(err).
			Error("Error sending map output to reducer")
		return err
	}

	// send metadata to sqs
	if err := m.SendMetadata(ctx, queuePartition); err != nil {
		mapperLogger.WithError(err).Error("Error sending metadata to streams")
		return err
	}

	// send event to queue indicating this mapper has completed
	if err := m.SendFinishedEvent(ctx); err != nil {
		mapperLogger.WithError(err).Error("Error sending done event to stream")
		return err
	}

	return nil
}

func main() {
	lambda.Start(HandleRequest)
}

`
